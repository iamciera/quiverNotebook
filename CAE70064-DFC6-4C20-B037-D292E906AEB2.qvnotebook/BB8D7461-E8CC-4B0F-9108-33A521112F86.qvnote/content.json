{
  "title": "Machine_learning_approaches",
  "cells": [
    {
      "type": "markdown",
      "data": "# Logical Regression \n\nClassification of enhancer expression during embryogenesis. \n\n1. Dataset is used to predict parameters\n2. Find decision boundry based on hypothesis and parameters of hypothesis\n\nParameters of hypothesis\n\n\n## Optimization Algorithms:\n\n1.  Conjugate gradient\n2.  BFGS\n3.  L - BFGS\n  \n\n## Sequence Features\n\nTranscription binding site\nCo-binding conservation (?)\n\n## Training Sets\n\n**On choosing the training set**: The training set can be selected by applying a random filter to the data, e.g., select 20% of the points at random to generate the model and test against the remaining 80%. If you want to be especially careful, then do this multiple times, i.e., select different random training sets and compare the models. If you get similar models then your model has probably captured the essential chemistry and physics of the problem. If the models are very different, then you are just fitting equations without a good physical basis.\n\nDividing Datasets: [Stack Overflow](http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)\n\n1. Stage specific \n2. Enhancer signal negative or possibly brain if you can get this data\n\n\n# Random Forest\n\nTwo classes are defined 1. Embryogenesis enhancer 2. negative enhancer.\n\n# Generalized Hidden Markov Models (gHMMs)\n\nUsed in Kaplan 2011. Allows integration of different forces that may influence transcription factor binding into the model.  Very few parameters therefore easy to optimize.  Posterior probabilities in linear time using the forward-backward dynamic programming algorithm.  Thermodynamic equilibrium models.  [Boltzman distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution) where each configuration assigned a weight or probability. \n\n## Resources\n\nVince's article is interesting: [The Unbelievable Debate: Some Ramblings on Machine Learning in Science](http://www.vincebuffalo.com/blog/2012/03/03/the-unbelievable-debate-some-ramblings-on-machine-learning-in-science.html)\n\n[Topic Modelling]()\n\nnetworkX \n\n[Normaliation and Feature Scaling](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)"
    },
    {
      "type": "diagram",
      "diagramType": "sequence",
      "data": ""
    }
  ]
}